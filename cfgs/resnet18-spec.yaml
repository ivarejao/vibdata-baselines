# Experiment overall settings
epochs: 80
batch_size: 64
seed: 42
model_checkpoint_gap: 1
# Training settings
optimizer:
  name: Adam
  parameters:
    lr: 0.0003
    weight_decay: 0.001
# Define the learning rates schedules that will be used.
# Can be 1 or more schedulers
lr_scheduler:
  - name: ExponentialLR
    parameters:
      gamma: 0.9
model:
  name: resnet18
  output_param: out_channel
  parameters:
    out_channel: 4
dataset:
  name: CWRU
  groups_dir: "data/groups"
  raw: 
    root: "data/raw_datasets"
  deep:
    root: "data/deep_datasets"
    transforms:
      - name: SplitSampleRate
      - name: StandardScaler
        parameters: 
          on_field: signal
      - name: Luciano
        parameters:
          size: [224, 224]
          transforms: ["spectrogram"]
          params:
            spectrogram:
              resolution: 0.125
              set_nperseg: False
              set_noverlap: False
          # image_examples: 1
      - name: FilterByValue
        parameters:
          on_field: sample_rate
          values: 12000
params_grid:
  lr: [0.01, 0.001, 0.0003]